import random
import re
from datasets import load_dataset, Dataset, DatasetDict
from tqdm import tqdm
from huggingface_hub import create_repo

# è¿‡æ»¤å‡½æ•°
def is_valid(sample):
    ans = sample.get("reference_answer", None)

    if not isinstance(ans, str):
        return False

    ans = ans.strip()

    if not ans:
        return False

    # çº¯æ•°å­—ã€æ ‡ç‚¹ç­‰
    if re.fullmatch(r"[\d\W\s]+", ans):
        return False

    # å°‘äº30å­—ç¬¦
    if len(ans) < 30:
        return False

    # å¤ªçŸ­ï¼ˆå•è¯å°‘ï¼‰
    if len(ans.split()) <= 10:
        return False

    # æ²¡æœ‰å®Œæ•´å¥å·æ•°é‡ï¼ˆé˜²æ­¢å¥å­ä¸å…¨ï¼‰
    if ans.count('.') + ans.count('!') + ans.count('?') <= 2:
        return False

    return True

# åŠ è½½æ•°æ®é›†
print("ğŸ“¦ Loading dataset...")
dataset = load_dataset("GeneralReasoning/GeneralThought-430K", split="train")

# è¿‡æ»¤æ ·æœ¬
print("ğŸ” Filtering samples...")
filtered = [sample for sample in tqdm(dataset) if is_valid(sample)]
print(f"âœ… Filtered samples: {len(filtered)}")

if len(filtered) < 5000:
    raise ValueError("âŒ Too few samples after filtering (<5000).")

# åˆ’åˆ†æ•°æ®é›†
random.seed(42)
random.shuffle(filtered)

train_data = filtered[:3000]
val_data = filtered[3000:4000]
test_data = filtered[4000:5000]

# æ„å»º DatasetDict
train_ds = Dataset.from_list(train_data)
val_ds = Dataset.from_list(val_data)
test_ds = Dataset.from_list(test_data)

final_ds = DatasetDict({
    "train": train_ds,
    "validation": val_ds,
    "test": test_ds
})

# åˆ›å»ºè¿œç¨‹ä»“åº“
repo_id = "guanning-ai/GeneralThought-430K-filtered"
print(f"ğŸš€ Creating repo: {repo_id}")
create_repo(repo_id, repo_type="dataset", exist_ok=True)

# ä¸Šä¼ æ•°æ®é›†åˆ° hub
print("â¬†ï¸ Pushing dataset to the Hub...")
final_ds.push_to_hub(repo_id)
print("âœ… Upload complete.")
